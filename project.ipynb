{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Module 2 Project  - Northwind Database Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Matthew Sparr <br><br> <center><h8>Self-Paced Data Science Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will connect to the database and grab all the table names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Employee',),\n",
       " ('Category',),\n",
       " ('Customer',),\n",
       " ('Shipper',),\n",
       " ('Supplier',),\n",
       " ('Order',),\n",
       " ('Product',),\n",
       " ('OrderDetail',),\n",
       " ('CustomerCustomerDemo',),\n",
       " ('CustomerDemographic',),\n",
       " ('Region',),\n",
       " ('Territory',),\n",
       " ('EmployeeTerritory',)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sql.connect('Northwind_small.sqlite')\n",
    "cur = conn.cursor()\n",
    "table_names = list(cur.execute('''SELECT name FROM sqlite_master WHERE TYPE = 'table'\n",
    "                               ''').fetchall())\n",
    "table_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will store each table from the database as Pandas Dataframe so that they are easy to work with and analyze. There was a technical error with the 'orders' table, so a CSV file of the table was generated using an outside program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_comm = []\n",
    "for i in range(0,len(table_names)):\n",
    "    s = \"SELECT * FROM \" + table_names[i][0]\n",
    "    sql_comm.append(s)\n",
    "\n",
    "employees = pd.read_sql_query(sql_comm[0], conn)\n",
    "categories = pd.read_sql_query(sql_comm[1], conn)\n",
    "customers = pd.read_sql_query(sql_comm[2], conn)\n",
    "shippers = pd.read_sql_query(sql_comm[3], conn)\n",
    "\n",
    "suppliers = pd.read_sql_query(sql_comm[4], conn)\n",
    "products = pd.read_sql_query(sql_comm[6], conn)\n",
    "order_details = pd.read_sql_query(sql_comm[7], conn)\n",
    "orders = pd.read_csv('Order.csv')\n",
    "\n",
    "cust_cust_demos = pd.read_sql_query(sql_comm[8], conn)\n",
    "cust_demos = pd.read_sql_query(sql_comm[9], conn)\n",
    "regions = pd.read_sql_query(sql_comm[10], conn)\n",
    "territories = pd.read_sql_query(sql_comm[11], conn)\n",
    "emp_territories = pd.read_sql_query(sql_comm[12], conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a schema of the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Northwind_ERD.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 -- Does discount amount have a statistically significant effect on the quantity of a product in an order? If so, at what level(s) of discount?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>H<sub>0: The average quantity of product ordered is the same for orders with and without a discount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>H<sub>a: The average quantity of product ordered when a discount is given is higher or lower than for orders without a discount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is our first question and both the null and alternative hypotheses. To test them will involve a two-tail test. This is because if the null hypothesis is rejected and there is a correlation between discount and order quantity, we could find that the discount amount either increases or decreases the quantity of product ordered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our hypotheses we will be using the table 'order_details' and will be looking only at the columns 'Quantity' and 'Discount'. Below we can see that there are no null or missing values in either column. Also, 'Quantity' ranges from 1 to 130 and 'Discount' ranges from 0 to 0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2155 entries, 0 to 2154\n",
      "Data columns (total 2 columns):\n",
      "Quantity    2155 non-null int64\n",
      "Discount    2155 non-null float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 33.8 KB\n"
     ]
    }
   ],
   "source": [
    "order_details[['Quantity','Discount']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2155.000000</td>\n",
       "      <td>2155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.812993</td>\n",
       "      <td>0.056167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.022047</td>\n",
       "      <td>0.083450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>130.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Quantity     Discount\n",
       "count  2155.000000  2155.000000\n",
       "mean     23.812993     0.056167\n",
       "std      19.022047     0.083450\n",
       "min       1.000000     0.000000\n",
       "25%      10.000000     0.000000\n",
       "50%      20.000000     0.000000\n",
       "75%      30.000000     0.100000\n",
       "max     130.000000     0.250000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_details[['Quantity','Discount']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will split our order details into two sets: discount and no discount. Running a t-test on the data below then gives us a small p-value of 1.14e-10 which is less than our alpha of 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1440924523215966e-10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_disc = order_details[order_details['Discount'] == 0].copy()\n",
    "disc = order_details[order_details['Discount'] > 0].copy()\n",
    "\n",
    "p = stats.ttest_ind(no_disc.Quantity, disc.Quantity)[1]\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value for our t-test is so low, this allows us to reject the null-hypothesis and accept instead the alternative hypothesis. From this result we can reasonably argue that having a discount does indeed have an impact on the quantity of product ordered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second part of the question we will need to look at the different discount amounts and see where the size of the discount affects the quantity ordered the most. Let's start by looking at the unique values in 'Discount' below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00    1317\n",
       "0.05     185\n",
       "0.10     173\n",
       "0.20     161\n",
       "0.15     157\n",
       "0.25     154\n",
       "0.03       3\n",
       "0.02       2\n",
       "0.01       1\n",
       "0.04       1\n",
       "0.06       1\n",
       "Name: Discount, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_details.Discount.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the count of some discount values are so few compared to others, we will group those discount values together. Below we create 5 buckets of discount values and then add them each to an array so we can iterate through them. We will also be filtering out data where there is no discount given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_5 = order_details['Quantity'][(order_details['Discount'] <= 0.05) & (order_details['Discount'] > 0)]\n",
    "disc_10 = order_details['Quantity'][(order_details['Discount'] > 0.05) & (order_details['Discount'] <= 0.1)]\n",
    "disc_15 = order_details['Quantity'][(order_details['Discount'] > 0.1) & (order_details['Discount'] <= 0.15)]\n",
    "disc_20 = order_details['Quantity'][(order_details['Discount'] > 0.15) & (order_details['Discount'] <= 0.2)]\n",
    "disc_25 = order_details['Quantity'][order_details['Discount'] > 0.2]\n",
    "discounts = []\n",
    "discounts.extend((['0.05 or less', disc_5], ['Between 0.05 and 0.10', disc_10],\n",
    "                  ['Between 0.10 and 0.15', disc_15], ['Between 0.15 and 0.20', disc_20],\n",
    "                  ['Greater than 0.20', disc_25]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then view the size of each of these buckets and notice that they are all fairly similar in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "174\n",
      "157\n",
      "161\n",
      "154\n"
     ]
    }
   ],
   "source": [
    "for i in discounts:\n",
    "    print(len(i[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this second part of the question, we will need a set of  null and alternative hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>H<sub>0: The average quantity of product ordered is the same for X and Y amount of discount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>H<sub>a: The average quantity of product ordered is different for X and Y amount of discount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above hypotheses, X and Y represent two discount levels. Since we have 5 buckets of individual discount amounts, we will start by declaring the lowest one (0.05 or less) X and the next level up (between 0.05 and 0.10) Y and then running our T-test and checking the p-value. We will then repeat this up to the highest discount level giving us 4 seperate hypotheses to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 or less v.s. Between 0.05 and 0.10 : 0.39367155112980046\n",
      "Between 0.05 and 0.10 v.s. Between 0.10 and 0.15 : 0.15837034442401487\n",
      "Between 0.10 and 0.15 v.s. Between 0.15 and 0.20 : 0.5433964640207652\n",
      "Between 0.15 and 0.20 v.s. Greater than 0.20 : 0.5801473824667989\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(discounts)-1):\n",
    "    X = discounts[i][1]\n",
    "    y = discounts[i+1][1]\n",
    "    p = stats.ttest_ind(X, y)[1]\n",
    "    print(discounts[i][0] + \" v.s. \" + discounts[i+1][0] + \" : \" + str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the above p-values are below our alpha of 0.05. Therefore we fail to reject the null-hypothesis and cannot conclude that increasing the discount at any level will significantly affect the quantity of product ordered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our findings show that having a discount on a product most likely will increase the quantity of product order but the actual amount of discount is statistically insignificant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 -- Are there certain products that are better to discount than others in order to increase the quantity ordered?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a follow-up to our initial question, we will investigate whether or not certain categories of items are more advantageous to discount if our goal is to increase total sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>H<sub>0: The average quantity of product ordered is the same regardless of category or discount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>H<sub>a: The average quantity of product ordered varies in correlation with category and discount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our hypothesis we will need data from more than one table so we will need to perform a couple merges. We will first join the 'products' table to the 'order-details' table as 'prod_ord_details'; and then merge that table with the 'categories' table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_x</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>SupplierId</th>\n",
       "      <th>CategoryId</th>\n",
       "      <th>QuantityPerUnit</th>\n",
       "      <th>UnitPrice_x</th>\n",
       "      <th>UnitsInStock</th>\n",
       "      <th>UnitsOnOrder</th>\n",
       "      <th>ReorderLevel</th>\n",
       "      <th>Discontinued</th>\n",
       "      <th>Id_y</th>\n",
       "      <th>OrderId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UnitPrice_y</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Id</th>\n",
       "      <th>CategoryName</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Chai</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10 boxes x 20 bags</td>\n",
       "      <td>18.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10285/1</td>\n",
       "      <td>10285</td>\n",
       "      <td>1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>45</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Soft drinks, coffees, teas, beers, and ales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Chai</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10 boxes x 20 bags</td>\n",
       "      <td>18.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10294/1</td>\n",
       "      <td>10294</td>\n",
       "      <td>1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Soft drinks, coffees, teas, beers, and ales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Chai</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10 boxes x 20 bags</td>\n",
       "      <td>18.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10317/1</td>\n",
       "      <td>10317</td>\n",
       "      <td>1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Soft drinks, coffees, teas, beers, and ales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Chai</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10 boxes x 20 bags</td>\n",
       "      <td>18.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10348/1</td>\n",
       "      <td>10348</td>\n",
       "      <td>1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Soft drinks, coffees, teas, beers, and ales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Chai</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10 boxes x 20 bags</td>\n",
       "      <td>18.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10354/1</td>\n",
       "      <td>10354</td>\n",
       "      <td>1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Soft drinks, coffees, teas, beers, and ales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id_x ProductName  SupplierId  CategoryId     QuantityPerUnit  UnitPrice_x  \\\n",
       "0     1        Chai           1           1  10 boxes x 20 bags         18.0   \n",
       "1     1        Chai           1           1  10 boxes x 20 bags         18.0   \n",
       "2     1        Chai           1           1  10 boxes x 20 bags         18.0   \n",
       "3     1        Chai           1           1  10 boxes x 20 bags         18.0   \n",
       "4     1        Chai           1           1  10 boxes x 20 bags         18.0   \n",
       "\n",
       "   UnitsInStock  UnitsOnOrder  ReorderLevel  Discontinued     Id_y  OrderId  \\\n",
       "0            39             0            10             0  10285/1    10285   \n",
       "1            39             0            10             0  10294/1    10294   \n",
       "2            39             0            10             0  10317/1    10317   \n",
       "3            39             0            10             0  10348/1    10348   \n",
       "4            39             0            10             0  10354/1    10354   \n",
       "\n",
       "   ProductId  UnitPrice_y  Quantity  Discount  Id CategoryName  \\\n",
       "0          1         14.4        45      0.20   1    Beverages   \n",
       "1          1         14.4        18      0.00   1    Beverages   \n",
       "2          1         14.4        20      0.00   1    Beverages   \n",
       "3          1         14.4        15      0.15   1    Beverages   \n",
       "4          1         14.4        12      0.00   1    Beverages   \n",
       "\n",
       "                                   Description  \n",
       "0  Soft drinks, coffees, teas, beers, and ales  \n",
       "1  Soft drinks, coffees, teas, beers, and ales  \n",
       "2  Soft drinks, coffees, teas, beers, and ales  \n",
       "3  Soft drinks, coffees, teas, beers, and ales  \n",
       "4  Soft drinks, coffees, teas, beers, and ales  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_ord_details = pd.merge(products, \n",
    "                  order_details,\n",
    "                  left_on='Id',\n",
    "                  right_on='ProductId',\n",
    "                  how='left')\n",
    "prod_cat = pd.merge(prod_ord_details, \n",
    "                  categories,\n",
    "                  left_on='CategoryId',\n",
    "                  right_on='Id',\n",
    "                  how='left')\n",
    "prod_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the head of the merged table we can see lots of variables we don't need. We will create a new DataFrame with only the categories we need: 'Quantity', 'Discount', and 'CategoryName'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>CategoryName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0.20</td>\n",
       "      <td>Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Beverages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quantity  Discount CategoryName\n",
       "0        45      0.20    Beverages\n",
       "1        18      0.00    Beverages\n",
       "2        20      0.00    Beverages\n",
       "3        15      0.15    Beverages\n",
       "4        12      0.00    Beverages"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_data = prod_cat[['Quantity', 'Discount', 'CategoryName']]\n",
    "q2_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know from before that there are a few 'Discount' values with signficantly less occurances than others, we will need to address that for this question. Let's view the value counts for 'Discount'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00    1317\n",
       "0.05     185\n",
       "0.10     173\n",
       "0.20     161\n",
       "0.15     157\n",
       "0.25     154\n",
       "0.03       3\n",
       "0.02       2\n",
       "0.01       1\n",
       "0.04       1\n",
       "0.06       1\n",
       "Name: Discount, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_data['Discount'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the low occurance rate 'Discount' values (0.01, 0.02, 0.03, 0.04, and 0.06) are all close to 0.05. We will simply adjust them each to 0.05 to give us a more equal distribution of discounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sparr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "q2_data['Discount'] = q2_data['Discount'].apply(lambda x: 0.05 if (x > 0 and x < 0.10) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to test the impact of a variable ('Discount') on the dependent variable ('Quantity') for multiple groups ('CategoryName'), we will use analysis of variance or ANOVA to test our hypothesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(CategoryName)</th>\n",
       "      <td>1148.391892</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.466377</td>\n",
       "      <td>8.593555e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(Discount)</th>\n",
       "      <td>15825.229259</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.997563</td>\n",
       "      <td>1.794405e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(CategoryName):C(Discount)</th>\n",
       "      <td>21108.931647</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.714522</td>\n",
       "      <td>5.838482e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>741173.098204</td>\n",
       "      <td>2107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sum_sq      df         F        PR(>F)\n",
       "C(CategoryName)                1148.391892     7.0  0.466377  8.593555e-01\n",
       "C(Discount)                   15825.229259     5.0  8.997563  1.794405e-08\n",
       "C(CategoryName):C(Discount)   21108.931647    35.0  1.714522  5.838482e-03\n",
       "Residual                     741173.098204  2107.0       NaN           NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = 'Quantity ~ C(CategoryName)*C(Discount)'\n",
    "lm = ols(formula, q2_data).fit()\n",
    "table = sm.stats.anova_lm(lm, typ=2)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results we can see that the p-value for the interaction between 'Discount' and 'CategoryName' is approx. 0.0058. Since this is less than our alpha of 0.05, we can reject the null hypothesis and accept the alternative hypothesis. This means that we can say there is evidence that the interaction of 'Discount' and 'CategoryName' has a statistically significant effect on the quantity of product ordered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do some additional analysis to look at each category individually to see if maybe certain categories show more of an effect on quantity when a discount is given. By using ANOVA again but this time having only one independent variable, 'Discount_bin', we can see the individual effect on 'Quantity' for each category. We will store the results in an array called 'results' with the 'CategoryName', F-value, and p-value in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "PatsyError",
     "evalue": "expected a noun, but instead the expression ended\n    Quantity ~\n             ^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-ab88050cb923>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mj_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Discount'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mformula\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Quantity ~ '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mlm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manova_lm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" + \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PR(>F)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         tmp = handle_formula_data(data, None, formula, depth=eval_env,\n\u001b[1;32m--> 155\u001b[1;33m                                   missing=missing)\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesign_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\formula\\formulatools.py\u001b[0m in \u001b[0;36mhandle_formula_data\u001b[1;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_using_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n\u001b[1;32m---> 65\u001b[1;33m                                NA_action=na_action)\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36mdmatrices\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[0meval_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n\u001b[1;32m--> 310\u001b[1;33m                                       NA_action, return_type)\n\u001b[0m\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mPatsyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model is missing required outcome variables\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36m_do_highlevel_design\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     design_infos = _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[1;32m--> 165\u001b[1;33m                                       NA_action)\n\u001b[0m\u001b[0;32m    166\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdesign_infos\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         return build_design_matrices(design_infos, data,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36m_try_incr_builders\u001b[1;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \"ascii-only, or else upgrade to Python 3.\")\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformula_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mformula_like\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelDesc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_formula\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformula_like\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;31m# fallthrough\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformula_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelDesc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\desc.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[1;34m(cls, tree_or_string)\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree_or_string\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_formula\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_or_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_evalexpr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\parse_formula.py\u001b[0m in \u001b[0;36mparse_formula\u001b[1;34m(code, extra_operators)\u001b[0m\n\u001b[0;32m    146\u001b[0m     tree = infix_parse(_tokenize_formula(code, operator_strings),\n\u001b[0;32m    147\u001b[0m                        \u001b[0moperators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                        _atomic_token_types)\n\u001b[0m\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParseNode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"~\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParseNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"~\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\infix_parser.py\u001b[0m in \u001b[0;36minfix_parse\u001b[1;34m(tokens, operators, atomic_types, trace)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwant_noun\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         raise PatsyError(\"expected a noun, but instead the expression ended\",\n\u001b[1;32m--> 222\u001b[1;33m                             c.op_stack[-1].token.origin)\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_stack\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPatsyError\u001b[0m: expected a noun, but instead the expression ended\n    Quantity ~\n             ^"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in q2_data['CategoryName'].unique():\n",
    "    i_data = q2_data[q2_data['CategoryName'] == i]\n",
    "    for j in i_data['Discount'].unique():\n",
    "        j_data = i_data[i_data['Discount'] == j]\n",
    "        formula = 'Quantity ~ '\n",
    "        lm = ols(formula, j_data).fit()\n",
    "        table = sm.stats.anova_lm(lm, typ=1)\n",
    "        results.append([str(i) + \" + \" + str(j), table['F'].iloc[0], table['PR(>F)'].iloc[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are doing some post-hoc testing, we need to use a Bonferroni correction to avoid p-hacking. The adjusted alpha is calculated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00625"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(q2_data['CategoryName'].unique())\n",
    "alpha = 0.05\n",
    "bon_alpha = alpha/n\n",
    "bon_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our new adjusted alpha, we can now view the results where the p-value is less than our 'bon_alpha' value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in results:\n",
    "    if i[2] < bon_alpha:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 3 of the categories produced results with significant probabilities. Out of these, 'Beverages' and 'Dairy Products' both have high F-values of ~13.74 and ~13.56 respectively, while 'Condiments' has a lesser F-value of ~9.1. From these results, it would suggest that for products in the categories of 'Beverages', 'Dairy Products', and 'Condiments', providing a discount will almost always increase the quantity of product sold. Furthermore, that increase in product sold will be highest in 'Beverages' and 'Dairy Products'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our findings show that having a discount on a product most likely will increase the quantity of product order but the actual amount of discount is statistically insignificant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "PatsyError",
     "evalue": "Error evaluating factor: NameError: name 'Discount_bin' is not defined\n    Quantity ~ C(CategoryName)*C(Discount_bin)\n                               ^^^^^^^^^^^^^^^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[1;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\eval.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, expr, source_name, inner_namespace)\u001b[0m\n\u001b[0;32m    165\u001b[0m         return eval(code, {}, VarLookupDict([inner_namespace]\n\u001b[1;32m--> 166\u001b[1;33m                                             + self._namespaces))\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Discount_bin' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-44b37a301662>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mformula\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Quantity ~ C(CategoryName)*C(Discount_bin)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq2_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manova_lm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         tmp = handle_formula_data(data, None, formula, depth=eval_env,\n\u001b[1;32m--> 155\u001b[1;33m                                   missing=missing)\n\u001b[0m\u001b[0;32m    156\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesign_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\formula\\formulatools.py\u001b[0m in \u001b[0;36mhandle_formula_data\u001b[1;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_using_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n\u001b[1;32m---> 65\u001b[1;33m                                NA_action=na_action)\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36mdmatrices\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[0meval_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n\u001b[1;32m--> 310\u001b[1;33m                                       NA_action, return_type)\n\u001b[0m\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mPatsyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model is missing required outcome variables\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36m_do_highlevel_design\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     design_infos = _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[1;32m--> 165\u001b[1;33m                                       NA_action)\n\u001b[0m\u001b[0;32m    166\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdesign_infos\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         return build_design_matrices(design_infos, data,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36m_try_incr_builders\u001b[1;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m     68\u001b[0m                                       \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                                       \u001b[0meval_env\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                                       NA_action)\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\build.py\u001b[0m in \u001b[0;36mdesign_matrix_builders\u001b[1;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m    694\u001b[0m                                                    \u001b[0mfactor_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m                                                    \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m                                                    NA_action)\n\u001b[0m\u001b[0;32m    697\u001b[0m     \u001b[1;31m# Now we need the factor infos, which encapsulate the knowledge of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;31m# how to turn any given factor into a chunk of data:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\build.py\u001b[0m in \u001b[0;36m_examine_factor_types\u001b[1;34m(factors, factor_states, data_iter_maker, NA_action)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamine_needed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactor_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfactor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcat_sniffers\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mguess_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcat_sniffers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\eval.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, memorize_state, data)\u001b[0m\n\u001b[0;32m    564\u001b[0m         return self._eval(memorize_state[\"eval_code\"],\n\u001b[0;32m    565\u001b[0m                           \u001b[0mmemorize_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m                           data)\n\u001b[0m\u001b[0;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[0m__getstate__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mno_pickling\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\eval.py\u001b[0m in \u001b[0;36m_eval\u001b[1;34m(self, code, memorize_state, data)\u001b[0m\n\u001b[0;32m    549\u001b[0m                                  \u001b[0mmemorize_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eval_env\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m                                  \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                                  inner_namespace=inner_namespace)\n\u001b[0m\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmemorize_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhich_pass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[1;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m                                  origin)\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# Use 'exec' to hide this syntax from the Python 2 parser:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"raise new_exc from e\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# In python 2, we just let the original exception escape -- better\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\patsy\\compat.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mPatsyError\u001b[0m: Error evaluating factor: NameError: name 'Discount_bin' is not defined\n    Quantity ~ C(CategoryName)*C(Discount_bin)\n                               ^^^^^^^^^^^^^^^"
     ]
    }
   ],
   "source": [
    "formula = 'Quantity ~ C(CategoryName)*C(Discount_bin)'\n",
    "lm = ols(formula, q2_data).fit()\n",
    "table = sm.stats.anova_lm(lm, typ=2)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's do what we did in the first question and place the 'Discount' values into buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_data['Discount'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_data['Discount'] = q2_data['Discount'].apply(lambda x: 0.05 if (x > 0 and x < 0.10) else x)\n",
    "q2_data['Discount'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "formula = 'Quantity ~ C(CategoryName)*C(Discount)'\n",
    "lm = ols(formula, q2_data).fit()\n",
    "table = sm.stats.anova_lm(lm, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.factorplots import interaction_plot\n",
    "fig = interaction_plot(q2_data.Discount, q2_data.CategoryName, q2_data.Quantity,\n",
    "             colors=['red','blue','green','yellow','purple','orange','pink', 'black'], ms=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "formula = 'Quantity ~ C(Discount)*C(CategoryName)'\n",
    "lm = ols(formula, q2_data).fit()\n",
    "table = sm.stats.anova_lm(lm, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'Quantity ~ C(CategoryName) + C(Discount)'\n",
    "lm = ols(formula, q2_data).fit()\n",
    "table = sm.stats.anova_lm(lm, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q2_data = q2_data.join(pd.get_dummies(q2_data['CategoryName']))\n",
    "q2_data.columns = [c.replace(' ', '_') for c in q2_data.columns]\n",
    "q2_data.columns = [c.replace('/', '_') for c in q2_data.columns]\n",
    "q2_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in q2_data['CategoryName'].unique():\n",
    "    data = q2_data[q2_data['CategoryName'] == i]\n",
    "    formula = 'Quantity ~ C(Disc)'\n",
    "    lm = ols(formula, data).fit()\n",
    "    table = sm.stats.anova_lm(lm, typ=2)\n",
    "    print(i)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = order_details['Quantity'][(order_details['Discount'] < 0.15) & (order_details['Discount'] > 0)]\n",
    "y = order_details['Quantity'][(order_details['Discount'] > 0.15)]\n",
    "p = stats.ttest_ind(X, y)[1]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.ShipCountry.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_countries = orders[['Id','ShipCountry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_disc_quan = order_details[['OrderId','Discount','Quantity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(order_countries, \n",
    "                  order_disc_quan,\n",
    "                  left_on='Id',\n",
    "                  right_on='OrderId',\n",
    "                  how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(pd.get_dummies(df.ShipCountry))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = \"+Discount*\".join(df.drop(['Quantity', 'OrderId', 'Id', 'Discount'], axis=1).columns)\n",
    "f = 'Quantity~' + columns\n",
    "round(ols(formula=f, data=df).fit().pvalues,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_details.Discount.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_05 = order_details[['Quantity','Discount']][(order_details.Discount<0.05) & (order_details.Discount>0)]\n",
    "disc_15 = order_details[['Quantity','Discount']][(order_details.Discount<0.15) & (order_details.Discount > 0.05)]\n",
    "disc_25 = order_details[['Quantity','Discount']][order_details.Discount>0.15]\n",
    "print(\"Less than 5% : \" + str(round(ols(formula='Quantity ~ Discount', data=disc_05).fit().pvalues[1],5)))\n",
    "print(\"Between 5% and 15% : \" + str(round(ols(formula='Quantity ~ Discount', data=disc_15).fit().pvalues[1],5)))\n",
    "print(\"Between 15% and 25% : \" + str(round(ols(formula='Quantity ~ Discount', data=disc_25).fit().pvalues[1],5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = 0\n",
    "for i in sorted(order_details.Discount.unique()):\n",
    "    d = order_details[['Quantity', 'Discount']][order_details.Discount==i].copy()\n",
    "    print(str(i)+ \" : \" + str(ols(formula='Quantity ~ Discount', data=d).fit().pvalues[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_5 = order_details['Quantity'][order_details['Discount'] <= 0.05]\n",
    "disc_10 = order_details['Quantity'][(order_details['Discount'] > 0.05) & (order_details['Discount'] <= 0.1)]\n",
    "disc_15 = order_details['Quantity'][(order_details['Discount'] > 0.1) & (order_details['Discount'] <= 0.15)]\n",
    "disc_20 = order_details['Quantity'][(order_details['Discount'] > 0.15) & (order_details['Discount'] <= 0.2)]\n",
    "disc_25 = order_details['Quantity'][order_details['Discount'] > 0.2]\n",
    "buckets = [(0.05, disc_5), (0.1, disc_10), (0.15, disc_15), (0.2, disc_20), (0.25,disc_25)]\n",
    "c = 0 \n",
    "while c < len(buckets) - 1:\n",
    "    x = buckets[c][1]\n",
    "    y = buckets[c+1][1]\n",
    "    p = stats.ttest_ind(x,y)[1]\n",
    "    print(str(buckets[c][0]) + \" v.s. \" + str(buckets[c+1][0]) + \" : \" + str(p)) \n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted(disc.Discount.unique(), reverse=True):\n",
    "    x = order_details['Quantity'][order_details['Discount'] <= i]\n",
    "    y = no_disc.Quantity\n",
    "    p = stats.ttest_ind(x,y)[1]\n",
    "    print(str(i) + \" or less : \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_details.Discount.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted(disc.Discount.unique()):\n",
    "    x = order_details['Quantity'][order_details['Discount'] >= i]\n",
    "    y = no_disc.Quantity\n",
    "    p = stats.ttest_ind(x,y)[1]\n",
    "    print(str(i) + \" or higher : \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_ord_details = pd.merge(products, \n",
    "                  order_details,\n",
    "                  left_on='Id',\n",
    "                  right_on='ProductId',\n",
    "                  how='left')\n",
    "prod_ord_details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_ord_details = pd.merge(products, \n",
    "                  order_details,\n",
    "                  left_on='Id',\n",
    "                  right_on='ProductId',\n",
    "                  how='left')\n",
    "prod_ord_details_cat = pd.merge(prod_ord_details, \n",
    "                  categories,\n",
    "                  left_on='CategoryId',\n",
    "                  right_on='Id',\n",
    "                  how='left')\n",
    "prod_ord_details_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_disc = prod_ord_details_cat.filter(['Quantity', 'Discount','CategoryName'], axis=1)\n",
    "df_cat_disc = prod_ord_details_cat.join(pd.get_dummies(df_cat_disc.CategoryName))\n",
    "df_cat_disc.CategoryName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = prod_ord_details_cat[['Quantity', 'Discount', 'CategoryName']].copy()\n",
    "a = a.join(pd.get_dummies(a.CategoryName))\n",
    "a.drop('CategoryName', axis=1, inplace=True)\n",
    "a.columns = [c.replace(' ', '_') for c in a.columns]\n",
    "a.columns = [c.replace('/', '_') for c in a.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = a.iloc[:,3:].columns\n",
    "for i in cats:\n",
    "    x = a['Quantity'][(a[i]== 1) & (a['Discount'] > 0)]\n",
    "    y = a['Quantity'][(a[i]== 1) & (a['Discount'] == 0)]\n",
    "    p = stats.ttest_ind(x,y)[1]\n",
    "    print(i + \" : \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_det = pd.merge(order_details, \n",
    "                  orders,\n",
    "                  left_on='OrderId',\n",
    "                  right_on='Id',\n",
    "                  how='left')\n",
    "ord_det_emp = pd.merge(ord_det,\n",
    "                      employees,\n",
    "                      left_on='EmployeeId',\n",
    "                      right_on='Id',\n",
    "                      how='left')\n",
    "ord_det_emp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ord_det_emp.Id.unique():\n",
    "    sales = (ord_det_emp['Quantity'][ord_det_emp['Id'] == i]) * (ord_det_emp['UnitPrice'][ord_det_emp['Id'] == i])\n",
    "    print (str(i) + \" \" + ord_det_emp['Title'][ord_det_emp['Id'] == i].unique() + \" : \" + str(round(sales.sum(),1)))\n",
    "    #print(ord_det_emp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sales(ID):\n",
    "    sales = (ord_det_emp['Quantity'][ord_det_emp['Id'] == ID]) * (ord_det_emp['UnitPrice'][ord_det_emp['Id'] == ID])\n",
    "    return sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_sales(ID):\n",
    "    sales = (ord_det_emp['Quantity'][ord_det_emp['Id'] == ID]) * (ord_det_emp['UnitPrice'][ord_det_emp['Id'] == ID])\n",
    "    return sales.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in [6,4,3,9,1,7]:\n",
    "    x.append(get_total_sales(i))\n",
    "y = []\n",
    "for i in [5,8,2]:\n",
    "    y.append(get_total_sales(i))\n",
    "stats.ttest_ind(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted(ord_det_emp.Id.unique()):\n",
    "    for j in sorted(ord_det_emp.Id.unique()):\n",
    "        if j <= i:\n",
    "            pass\n",
    "        else:\n",
    "            x = get_sales(i)\n",
    "            y = get_sales(j)\n",
    "            p = stats.ttest_ind(x,y)[1]\n",
    "            if p <= 0.05:\n",
    "                print(str(i) + \" v.s. \" + str(j) + \" : \" + str(round(p,3)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_det_emp.BirthDate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_det_emp.Id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps_data = []\n",
    "for i in sales_reps_IDs:\n",
    "    ord = orders['Id'][orders['EmployeeId'] == i]\n",
    "    details = []\n",
    "    for j in ord:\n",
    "        details.append(order_details[order_details['OrderId'] == j])\n",
    "    reps_data.append([i, details])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(reps_data)):\n",
    "    print(pd.DataFrame(reps_data[i][1][1].info()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.EmployeeId.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
